{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Processing to generate training set clips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temporal_annotations(annotation_file, fps = 30, skiprows = 1):\n",
    "    \"\"\"Read annotations as seconds for given animals in a file\n",
    "\n",
    "    Args:\n",
    "        annotation_file (str): path to annotation file\n",
    "        skiprows (int, optional): number of rows to skip in annotation file. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        dict: list of start, stops for each animal \n",
    "    \"\"\"\n",
    "    via_output = pd.read_csv(annotation_file, skiprows = skiprows)\n",
    "    via_output['behavior'] = via_output['metadata'].apply(lambda x: x.split('\"TEMPORAL-SEGMENTS\":\"')[-1][:-2].title())\n",
    "    via_output['frame_start'] = round(via_output['temporal_segment_start']*30).astype(int)\n",
    "    via_output['frame_end'] = round(via_output['temporal_segment_end']*30).astype(int)\n",
    "    \n",
    "    return via_output.loc[:,['behavior', 'frame_start', 'frame_end', 'temporal_segment_start', 'temporal_segment_end']].sort_values(by = 'frame_start').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_crop(x, y, buffer = 200, shape = [1080, 1920]):\n",
    "    \n",
    "    if (x + buffer) >  shape[1]:\n",
    "        max_x = shape[1]\n",
    "    else:\n",
    "        max_x = x+buffer\n",
    "\n",
    "    if (x - buffer) < 0:\n",
    "        min_x = 0\n",
    "    else:\n",
    "        min_x = x-buffer\n",
    "\n",
    "    if (y + buffer) >  shape[0]:\n",
    "        max_y = shape[0]\n",
    "    else:\n",
    "        max_y = y+buffer\n",
    "\n",
    "    if (y - buffer) < 0:\n",
    "        min_y = 0\n",
    "    else:\n",
    "        min_y = y - buffer\n",
    "\n",
    "    # print(f\"Min y: {min_y}, Max y: {max_y}, Min x: {min_x}, Max x: {max_x}\")\n",
    "    cc = [round(min_y, 1), round(max_y, 1), round(min_x,1), round(max_x,1)]\n",
    "    center = [round(x, 1),round(y, 1)]\n",
    "    return [round(c) for c in cc], [round(c) for c in center]\n",
    "\n",
    "\n",
    "\n",
    "def padcrop_image(frame, buffer, cc, center):\n",
    "\n",
    "    padded_image = np.zeros((buffer*2, buffer*2, 3), dtype=np.uint8)\n",
    "     \n",
    "    # Paste the cropped region onto the black image\n",
    "    padded_image[\n",
    "        max(0, buffer - (center[1] - cc[0])):min(buffer*2, buffer + (cc[1] - center[1])),\n",
    "        max(0, buffer - (center[0] - cc[2])):min(buffer*2, buffer + (cc[3] - center[0])),:] = frame[cc[0]:cc[1], cc[2]:cc[3],:]\n",
    "\n",
    "    return padded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_behavior_clips(vid, ann_table, folder, crop_center= None, buffer = None, fps = 30, frame_shape = [1080, 1920, 3], an_suffix = None):\n",
    "    \n",
    "    writers = {k:None for k in ann_table['behavior'].unique()}\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "    start = ann_table.loc[0, 'frame_start']\n",
    "    \n",
    "\n",
    "    if start > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(start-1))\n",
    "    frame_count = start\n",
    "    reading = True\n",
    "\n",
    "    if buffer is not None:\n",
    "        out_shape = (buffer *2, buffer *2, 3)\n",
    "    else:\n",
    "        out_shape = frame_shape\n",
    "\n",
    "    while reading:\n",
    "        if frame_count > frames:\n",
    "            reading = False\n",
    "            for k,v in writers.items():\n",
    "                if v is not None:\n",
    "                    v.release()\n",
    "        else:\n",
    "            \n",
    "            current_table = ann_table.loc[(frame_count < ann_table['frame_end']) & (frame_count >= ann_table['frame_start']),:]\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f'Could not read frame {frame_count}')\n",
    "                break \n",
    "            # print(f'Current Frame: {frame_count}')\n",
    "            for _, row in current_table.iterrows():\n",
    "                \n",
    "                if (frame_count == row['frame_start']) or (writers[row['behavior']] is None):\n",
    "                    base_name, _ = os.path.splitext(os.path.basename(vid))\n",
    "                    if an_suffix is not None:\n",
    "                        base_name = base_name + '_'+ an_suffix\n",
    "                    write_name = os.path.join(folder, row['behavior'], base_name + '_'+ str(int(row['frame_start']))+ '_'+str(int(row['frame_end'])) +'.mp4')\n",
    "                    writer = cv2.VideoWriter(write_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, out_shape[:2])\n",
    "                    writers[row['behavior']] = writer\n",
    "                else:\n",
    "                    writer = writers[row['behavior']]\n",
    "                \n",
    "\n",
    "                if crop_center is not None:\n",
    "                    \n",
    "                    cc, center = frame_crop(crop_center[0], crop_center[1], buffer = buffer, shape = frame.shape)\n",
    "                    # print(f'Crop Center: {cc}')\n",
    "                    # print(f'Center: {center}')\n",
    "                    pc = padcrop_image(frame, buffer, cc, center)\n",
    "                    writer.write(pc)\n",
    "                    # print(write_name)\n",
    "                    # print(f'Wrote frame #{frame_count}')\n",
    "                else:\n",
    "                    writer.write(frame)\n",
    "                \n",
    "                if (frame_count + 1) > row['frame_end']:\n",
    "                    writer.release()\n",
    "                    writers[row['behavior']] = None\n",
    "        \n",
    "\n",
    "            frame_count = frame_count + 1\n",
    "            if frame_count > ann_table.loc[ann_table.shape[0]-1, 'frame_end']:\n",
    "                reading = False\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_from_vid(vid_path, animals = ['m1','m2','m3','m4','m5','m6'], dp = 0.5, minDist = 400):\n",
    "    src = cv2.VideoCapture(str(vid_path))\n",
    "    frames = src.get(cv2.CAP_PROP_FRAME_COUNT) \n",
    "    fps = src.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    ret = False\n",
    "    count = 0\n",
    "\n",
    "    while not ret:\n",
    "        ret, frame = src.read() \n",
    "        count = count +1\n",
    "        if count > frames:\n",
    "            return None\n",
    "    src.release()\n",
    "     \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp, minDist)\n",
    "    # print(circles)\n",
    "\n",
    "    if len(animals) > 1:\n",
    "        found = match_circles(circles[0])\n",
    "        dat = {}\n",
    "        for f, a in zip(found[0], animals):\n",
    "            dat[a] = f\n",
    "    else:\n",
    "        dat = {}\n",
    "        if circles is not None:\n",
    "            x_dif = np.argmin(abs(circles[0][:,0] - (frame.shape[1]/2)))\n",
    "            dat[animals] = circles[0][x_dif,:]\n",
    "        else:\n",
    "            dat[animals] = np.array([frame.shape[1]/2, frame.shape[0]/2, 350])\n",
    "        # plot_circles(vid_path, np.array( [[dat['1']]]), radius = 400)\n",
    "    return dat, frames, fps, frame.shape\n",
    "\n",
    "\n",
    "def match_circles(circles, x_exp = np.array([350, 980, 1560]), y_exp = np.array([285, 800]), distance = 100):\n",
    "\n",
    "    found = np.full([1,6,3], np.nan)\n",
    "    x_displace = np.zeros((6))\n",
    "    y_displace = np.zeros((6))\n",
    "    for c in circles:\n",
    "        # print(c)\n",
    "        x_dis = x_exp - c[0]\n",
    "        x_match = np.where(np.abs(x_dis) <= distance)[0]\n",
    "\n",
    "        y_dis = y_exp - c[1]\n",
    "        y_match = np.where(np.abs(y_exp - c[1]) <= distance)[0]\n",
    "\n",
    "        \n",
    "        if len(x_match) and len(y_match):\n",
    "            id = (3* y_match)+ x_match \n",
    "            found[0,id,:] = c\n",
    "            x_displace[id]= x_dis[x_match[0]]\n",
    "            y_displace[id] = y_dis[y_match[0]]\n",
    "\n",
    "    x_displace[x_displace == 0] = np.nan\n",
    "    y_displace[y_displace == 0] = np.nan\n",
    "\n",
    "    for v in np.argwhere(np.isnan(found)):\n",
    "        # print(v[1])\n",
    "        if v[2] == 0: # x\n",
    "            start = np.mod(v[1], 3)\n",
    "            dis = np.nanmean(x_displace[start::3])\n",
    "            if np.isnan(dis):\n",
    "                dis = np.nanmean(x_displace)\n",
    "            found[v[0], v[1], v[2]] = x_exp[start] - dis\n",
    "        if v[2] == 1: # y\n",
    "            if v[1] < 3:\n",
    "                dis = np.nanmean(y_displace[:3])\n",
    "                row = 0\n",
    "            else:\n",
    "                dis = np.nanmean(y_displace[3:])\n",
    "                row = 1\n",
    "            found[v[0], v[1], v[2]] = y_exp[row] - dis\n",
    "\n",
    "        if v[2] == 2: # r\n",
    "            found[v[0], v[1], v[2]] = np.nanmean(found[0,:,2])\n",
    "\n",
    "        \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid = '/Users/rebeccakrall/Desktop/Mouse Videos/PRX02_D8FR2C20_71.mp4'\n",
    "# dat, frames, fps, shape = get_params_from_vid(vid, animals = 'a')\n",
    "# annotation_file = \"/Users/rebeccakrall/Desktop/Mouse Videos/full_annoations_71.csv\"\n",
    "# ann_table = read_temporal_annotations(annotation_file)\n",
    "# generate_behavior_clips(vid, ann_table, folder = \"/Users/rebeccakrall/Desktop/Behavior Clips\", crop_center= None, buffer = None, fps = fps, frame_shape = shape, frames = frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multi_animal_annotations(annotation_file, animals, skiprows = 9):\n",
    "    \"\"\"Load annotations as seconds for given animals in a file\n",
    "\n",
    "    Args:\n",
    "        annotation_file (str): path to annotation file\n",
    "        animals (list): list of str indicating animals to load\n",
    "        skiprows (int, optional): number of rows to skip in annotation file. Defaults to 9.\n",
    "\n",
    "    Returns:\n",
    "        dict: list of start, stops for each animal \n",
    "    \"\"\"\n",
    "    via_output = pd.read_csv(annotation_file, skiprows = skiprows)\n",
    "    tc = via_output['temporal_coordinates']\n",
    "    tp = np.array([(np.array(literal_eval(a)) ) for a in tc])\n",
    "\n",
    "    d = {}\n",
    "    for k in animals:\n",
    "        d[k] = tp[via_output['metadata'].str.contains(k),:]\n",
    "        d[k][:,0].sort()\n",
    "        d[k][:,1].sort()\n",
    "\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_off_clips(off, frame_count): ## want to improve this so that it samples better\n",
    "#     off_starts = []\n",
    "#     random.shuffle(frame_count)\n",
    "#     for x,y  in zip(off, frame_count):\n",
    "#         if (x[1] - x[0]) > y:\n",
    "#             s = random.randint(x[0], x[1]- y)\n",
    "#             e = s + y\n",
    "#         else:\n",
    "#             s = x[0]\n",
    "#             e = x[1]\n",
    "\n",
    "#         off_starts.append([s,e])\n",
    "\n",
    "#     return off_starts\n",
    "\n",
    "def random_off_clips(off, frame_count): ## want to improve this so that it samples better\n",
    "    off_starts = []\n",
    "    \n",
    "    off2 = list(off[(off[:,1] - off[:,0]) > min(frame_count),:]) # choose only off epochs with sufficient \n",
    "    if len(off2) < 1:\n",
    "        return None, None\n",
    "    \n",
    "    random.shuffle(frame_count)\n",
    "    for y  in frame_count:\n",
    "    \n",
    "        matching = True\n",
    "        while matching:\n",
    "            if len(off2) < 1:\n",
    "                off2 = list(off[(off[:,1] - off[:,0]) > min(frame_count),:])\n",
    "            x = off2.pop()\n",
    "            if (x[1] - x[0]) > y:\n",
    "                s = random.randint(x[0], x[1]- y)\n",
    "                e = s + y\n",
    "                if (s - x[0]) > min(frame_count):\n",
    "                    off2.append(np.array([x[0], s]))\n",
    "                if (x[1] - e) > min(frame_count):\n",
    "                    off2.append(np.array([e, x[1]]))\n",
    "                matching = False\n",
    "\n",
    "        off_starts.append([s,e])\n",
    "\n",
    "    return off_starts, off2\n",
    "\n",
    "def on_off_behavior_table(anns, total_frames, fps = 30, behavior_name = 'scratch', random_off = True):\n",
    "    on = np.round(anns * fps).astype(int)\n",
    "    all_frames = np.insert(on.flatten(), 0, 0) \n",
    "    all_frames = np.append(all_frames, total_frames)\n",
    "    off = all_frames.reshape(-1,2)\n",
    "    if random_off:\n",
    "        frame_count = on[:,1] - on[:,0]\n",
    "        off, remainder = random_off_clips(off, frame_count)\n",
    "        off = np.array(off)\n",
    "    label = [behavior_name] * on.shape[0] + ['not_'+behavior_name]* off.shape[0]\n",
    "    frames = np.vstack([on, off])\n",
    "    tbl =  pd.DataFrame({'behavior': label, 'frame_start':frames[:,0], 'frame_end': frames[:,1]})\n",
    "    return tbl.sort_values('frame_start').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"/Users/rebeccakrall/Data/Video Processing and Prediction/Clean Training Data/MP4 Clips & DLC/PRX_02_D8_Female_run2_comp2_m67-72clip_0.mp4\"\n",
    "annotation_file = \"/Users/rebeccakrall/Data/Video Processing and Prediction/Clean Training Data/VIA CSV annotations/PRX_02_D8_Female_run2_comp2_m67-72clip_0_annotation.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_folder = \"/Users/rebeccakrall/Data/Video Processing and Prediction/Clean Training Data/VIA CSV annotations\"\n",
    "vid_folder = \"/Users/rebeccakrall/Data/Video Processing and Prediction/Clean Training Data/MP4 Clips & DLC\"\n",
    "\n",
    "all_ann = os.listdir(ann_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = all_ann.pop(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/m9j8_ntd13l1fhyf0w__ydsr0000gp/T/ipykernel_59711/824941781.py:63: RuntimeWarning: Mean of empty slice\n",
      "  dis = np.nanmean(x_displace[start::3])\n"
     ]
    }
   ],
   "source": [
    "for ex in all_ann:\n",
    "    vid = os.path.join(vid_folder, ex.split('_annotation')[0]+'.mp4')\n",
    "    dat, frames, fps, shape = get_params_from_vid(vid, animals = ['m1','m2','m3','m4','m5','m6'])\n",
    "    d = load_multi_animal_annotations(os.path.join(ann_folder, ex), ['m1','m2','m3','m4','m5','m6'])\n",
    "    for k in d.keys():\n",
    "        if len(d[k]):\n",
    "            tbl = on_off_behavior_table(d[k], frames, fps = fps, behavior_name = 'scratch')\n",
    "            generate_behavior_clips(vid, tbl, folder = \"/Users/rebeccakrall/Desktop/Scratching Clips\", crop_center = dat[k], buffer = 300, fps = fps, frame_shape = shape, an_suffix = k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = d['m2']\n",
    "on = np.round(anns * fps).astype(int)\n",
    "all_frames = np.insert(on.flatten(), 0, 0) \n",
    "all_frames = np.append(all_frames, 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = on[:,1] - on[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "off = all_frames.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 4308],\n",
       "       [4433, 5775],\n",
       "       [5872, 6115],\n",
       "       [6158, 6175],\n",
       "       [6365, 6390],\n",
       "       [6523, 8117],\n",
       "       [8283, 8444],\n",
       "       [8498, 8514],\n",
       "       [8609, 9000]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off = off[(off[:,1] - off[:,0]) > 15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = np.round(d['m1'] * fps).astype(int)\n",
    "all_frames = np.insert(on.flatten(), 0, 0) \n",
    "all_frames = np.append(all_frames, 9000)\n",
    "off = all_frames.reshape(-1,2)\n",
    "frame_count = on[:,1] - on[:,0]\n",
    "off, off2 = random_off_clips(off, frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8813 8850] too small for 55\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8952, 8983],\n",
       " [8667, 8691],\n",
       " [8850, 8896],\n",
       " [8905, 8935],\n",
       " [8776, 8813],\n",
       " [8707, 8762]]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dir = \"/Users/rebeccakrall/Desktop/Scratching Clips/not_scratch\"\n",
    "left_dir = \"/Users/rebeccakrall/Desktop/Behavior Clips/Left Foot Scratch\"\n",
    "right_dir = \"/Users/rebeccakrall/Desktop/Behavior Clips/Right Foot Scratch\"\n",
    "end_dir = \"/Users/rebeccakrall/Desktop/Behavior Clips\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('video_labels2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in df.iterrows():\n",
    "    if row['Label'] == 'L':\n",
    "        pass\n",
    "        # os.rename(os.path.join(start_dir, row['Video']), os.path.join(left_dir, row['Video']))\n",
    "        # print(f\"{row['Video']} left\")\n",
    "    elif row['Label'] == 'R':\n",
    "        # os.rename(os.path.join(start_dir, row['Video']), os.path.join(right_dir, row['Video']))\n",
    "        # print('right')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Groomiong directory does not exist\n",
      "Face Groomoing directory does not exist\n"
     ]
    }
   ],
   "source": [
    "for ind,row in df.iterrows():\n",
    "    if pd.notnull(row['Label']):\n",
    "        new_dir = os.path.join(end_dir, row['Label'])\n",
    "        if os.path.isdir(new_dir):\n",
    "                os.rename(os.path.join(start_dir, row['Video']), os.path.join(new_dir, row['Video']))\n",
    "        else:\n",
    "                print(f'{row[\"Label\"]} directory does not exist')\n",
    "    else:\n",
    "        new_dir = os.path.join(end_dir, 'Not Scratch')\n",
    "        if os.path.isdir(new_dir):\n",
    "                os.rename(os.path.join(start_dir, row['Video']), os.path.join(new_dir, row['Video']))\n",
    "        else:\n",
    "            print(f'{row[\"Label\"]} directory does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
